{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df34_old = pd.read_csv('to_analyze34.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liveness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>energy</th>\n",
       "      <th>danceability</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.4010</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2720</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0936</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.4680</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170648</th>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170649</th>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.1760</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170650</th>\n",
       "      <td>0.2740</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.2540</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170651</th>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170652</th>\n",
       "      <td>0.3430</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170653 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        liveness  acousticness  energy  danceability  instrumentalness  label\n",
       "0         0.1130        0.4010  0.5730         0.731          0.000052      1\n",
       "1         0.2720        0.2210  0.7220         0.700          0.000000      1\n",
       "2         0.0936        0.0112  0.7650         0.746          0.000000      1\n",
       "3         0.0824        0.0194  0.4540         0.935          0.000000      1\n",
       "4         0.0931        0.4680  0.8020         0.737          0.000000      1\n",
       "...          ...           ...     ...           ...               ...    ...\n",
       "170648    0.0979        0.9920  0.0082         0.224          0.865000      0\n",
       "170649    0.1050        0.1530  0.1760         0.700          0.000036      0\n",
       "170650    0.2740        0.9770  0.2540         0.517          0.000189      0\n",
       "170651    0.1070        0.1610  0.2380         0.699          0.000000      0\n",
       "170652    0.3430        0.7660  0.5740         0.234          0.877000      0\n",
       "\n",
       "[170653 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing lda on 34\n",
    "\n",
    "# Define the features to keep\n",
    "features_to_keep = ['liveness', 'acousticness', 'energy', 'danceability', 'instrumentalness', 'label']\n",
    "\n",
    "# Drop all features except the ones to keep\n",
    "df34_lda = df34_old[features_to_keep]\n",
    "\n",
    "df34_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8023908234570253\n",
      "Test Accuracy: 0.7196390378248513\n",
      "Precision:  0.7100475790652113\n",
      "Recall:  0.742942485650697\n",
      "F1:  0.7261226709407825\n",
      "Model Accuracy: 0.7196390378248513\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df34_lda.drop('label', axis=1)\n",
    "y = df34_lda['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the KNN model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training set\n",
    "y_train_pred = knn.predict(X_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model for the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Calculate the accuracy of the model for the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the test set\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "print(\"Precision: \", precision)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "print(\"Recall: \", recall)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "# Calculate the overall accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7336253497604782\n",
      "Test Accuracy: 0.7338196947056927\n",
      "Model Accuracy: 0.7336642192050535\n",
      "Precision: 0.733010558245348\n",
      "Recall: 0.7359728241771114\n",
      "F1 Score: 0.7344887044451589\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df34_lda.drop('label', axis=1)\n",
    "y = df34_lda['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the Logistic Regression model to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training set\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model for the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Calculate the accuracy of the model for the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the test set\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy of the model\n",
    "overall_accuracy = accuracy_score(y, logreg.predict(X))\n",
    "print(\"Model Accuracy:\", overall_accuracy)\n",
    "\n",
    "# Print precision, recall, and F1 score\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liveness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>energy</th>\n",
       "      <th>danceability</th>\n",
       "      <th>valence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.4010</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2720</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0936</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.7370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.4680</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.6820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170648</th>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170649</th>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.1760</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.4910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170650</th>\n",
       "      <td>0.2740</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.2540</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.4440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170651</th>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170652</th>\n",
       "      <td>0.3430</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170653 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        liveness  acousticness  energy  danceability  valence  label\n",
       "0         0.1130        0.4010  0.5730         0.731   0.1450      1\n",
       "1         0.2720        0.2210  0.7220         0.700   0.7560      1\n",
       "2         0.0936        0.0112  0.7650         0.746   0.7370      1\n",
       "3         0.0824        0.0194  0.4540         0.935   0.3570      1\n",
       "4         0.0931        0.4680  0.8020         0.737   0.6820      1\n",
       "...          ...           ...     ...           ...      ...    ...\n",
       "170648    0.0979        0.9920  0.0082         0.224   0.0696      0\n",
       "170649    0.1050        0.1530  0.1760         0.700   0.4910      0\n",
       "170650    0.2740        0.9770  0.2540         0.517   0.4440      0\n",
       "170651    0.1070        0.1610  0.2380         0.699   0.6120      0\n",
       "170652    0.3430        0.7660  0.5740         0.234   0.1440      0\n",
       "\n",
       "[170653 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing lasso on 34\n",
    "\n",
    "# Define the features to keep\n",
    "features_to_keep = ['liveness', 'acousticness', 'energy', 'danceability', 'valence', 'label']\n",
    "\n",
    "# Drop all features except the ones to keep\n",
    "df34_lasso = df34_old[features_to_keep]\n",
    "\n",
    "df34_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.809005142028391\n",
      "Test Accuracy: 0.7289853798599514\n",
      "Precision:  0.7245436804040868\n",
      "Recall:  0.7393112334543751\n",
      "F1:  0.7318529684601113\n",
      "Model Accuracy: 0.7289853798599514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df34_lasso.drop('label', axis=1)\n",
    "y = df34_lasso['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the KNN model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training set\n",
    "y_train_pred = knn.predict(X_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model for the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Calculate the accuracy of the model for the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the test set\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "print(\"Precision: \", precision)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "print(\"Recall: \", recall)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "# Calculate the overall accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7433820190152503\n",
      "Test Accuracy: 0.7431074389850869\n",
      "Model Accuracy: 0.7433271023656192\n",
      "Precision: 0.7505127277114247\n",
      "Recall: 0.7287103197844677\n",
      "F1 Score: 0.7394508498751932\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df34_lasso.drop('label', axis=1)\n",
    "y = df34_lasso['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the Logistic Regression model to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training set\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model for the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Calculate the accuracy of the model for the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the test set\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy of the model\n",
    "overall_accuracy = accuracy_score(y, logreg.predict(X))\n",
    "print(\"Model Accuracy:\", overall_accuracy)\n",
    "\n",
    "# Print precision, recall, and F1 score\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df50_old = pd.read_csv('to_analyze50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>valence</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.731</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7560</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.746</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7370</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.737</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6820</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170648</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170649</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.1760</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4910</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170650</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.2540</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4440</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170651</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>0.9130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170652</th>\n",
       "      <td>0.234</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170653 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        danceability  energy  explicit  valence  speechiness  label\n",
       "0              0.731  0.5730         1   0.1450       0.0544      1\n",
       "1              0.700  0.7220         1   0.7560       0.0369      1\n",
       "2              0.746  0.7650         0   0.7370       0.0993      1\n",
       "3              0.935  0.4540         1   0.3570       0.3750      1\n",
       "4              0.737  0.8020         1   0.6820       0.0878      1\n",
       "...              ...     ...       ...      ...          ...    ...\n",
       "170648         0.224  0.0082         0   0.0696       0.0350      0\n",
       "170649         0.700  0.1760         1   0.4910       0.9120      0\n",
       "170650         0.517  0.2540         0   0.4440       0.1200      0\n",
       "170651         0.699  0.2380         1   0.6120       0.9130      0\n",
       "170652         0.234  0.5740         0   0.1440       0.0481      0\n",
       "\n",
       "[170653 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing lda on 50\n",
    "\n",
    "# Define the features to keep\n",
    "features_to_keep = ['danceability', 'energy', 'explicit', 'valence', 'speechiness', 'label']\n",
    "\n",
    "# Drop all features except the ones to keep\n",
    "df50_lda = df50_old[features_to_keep]\n",
    "\n",
    "df50_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8360264279749784\n",
      "Test Accuracy: 0.7768304473938649\n",
      "Precision:  0.5017013232514178\n",
      "Recall:  0.3476096922069417\n",
      "F1:  0.41067698259187624\n",
      "Model Accuracy: 0.7768304473938649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df50_lda.drop('label', axis=1)\n",
    "y = df50_lda['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the KNN model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training set\n",
    "y_train_pred = knn.predict(X_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model for the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Calculate the accuracy of the model for the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the test set\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "print(\"Precision: \", precision)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "print(\"Recall: \", recall)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "# Calculate the overall accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7880341629920452\n",
      "Test Accuracy: 0.791304093053236\n",
      "Model Accuracy: 0.7886881566687958\n",
      "Precision: 0.5846001321877066\n",
      "Recall: 0.23169613621480026\n",
      "F1 Score: 0.33186380264515525\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df50_lda.drop('label', axis=1)\n",
    "y = df50_lda['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the Logistic Regression model to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training set\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model for the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Calculate the accuracy of the model for the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the test set\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy of the model\n",
    "overall_accuracy = accuracy_score(y, logreg.predict(X))\n",
    "print(\"Model Accuracy:\", overall_accuracy)\n",
    "\n",
    "# Print precision, recall, and F1 score\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>valence</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.731</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7560</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.746</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7370</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.737</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6820</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170648</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170649</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.1760</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4910</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170650</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.2540</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4440</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170651</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>0.9130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170652</th>\n",
       "      <td>0.234</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170653 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        danceability  energy  explicit  valence  speechiness  label\n",
       "0              0.731  0.5730         1   0.1450       0.0544      1\n",
       "1              0.700  0.7220         1   0.7560       0.0369      1\n",
       "2              0.746  0.7650         0   0.7370       0.0993      1\n",
       "3              0.935  0.4540         1   0.3570       0.3750      1\n",
       "4              0.737  0.8020         1   0.6820       0.0878      1\n",
       "...              ...     ...       ...      ...          ...    ...\n",
       "170648         0.224  0.0082         0   0.0696       0.0350      0\n",
       "170649         0.700  0.1760         1   0.4910       0.9120      0\n",
       "170650         0.517  0.2540         0   0.4440       0.1200      0\n",
       "170651         0.699  0.2380         1   0.6120       0.9130      0\n",
       "170652         0.234  0.5740         0   0.1440       0.0481      0\n",
       "\n",
       "[170653 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing lasso on 50\n",
    "\n",
    "# Define the features to keep\n",
    "features_to_keep = ['danceability', 'energy', 'explicit', 'valence', 'speechiness', 'label']\n",
    "\n",
    "# Drop all features except the ones to keep\n",
    "df50_lasso = df50_old[features_to_keep]\n",
    "\n",
    "df50_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8360264279749784\n",
      "Test Accuracy: 0.7768304473938649\n",
      "Precision:  0.5017013232514178\n",
      "Recall:  0.3476096922069417\n",
      "F1:  0.41067698259187624\n",
      "Model Accuracy: 0.7768304473938649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df50_lasso.drop('label', axis=1)\n",
    "y = df50_lasso['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the KNN model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training set\n",
    "y_train_pred = knn.predict(X_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model for the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Calculate the accuracy of the model for the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the test set\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "print(\"Precision: \", precision)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "print(\"Recall: \", recall)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "# Calculate the overall accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7880341629920452\n",
      "Test Accuracy: 0.791304093053236\n",
      "Model Accuracy: 0.7886881566687958\n",
      "Precision: 0.5846001321877066\n",
      "Recall: 0.23169613621480026\n",
      "F1 Score: 0.33186380264515525\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df50_lasso.drop('label', axis=1)\n",
    "y = df50_lasso['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the Logistic Regression model to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training set\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model for the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Calculate the accuracy of the model for the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the test set\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy of the model\n",
    "overall_accuracy = accuracy_score(y, logreg.predict(X))\n",
    "print(\"Model Accuracy:\", overall_accuracy)\n",
    "\n",
    "# Print precision, recall, and F1 score\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
