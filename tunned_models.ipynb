{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df34_old = pd.read_csv('to_analyze34.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_billboard</th>\n",
       "      <th>liveness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>energy</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.4010</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.4680</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170648</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170649</th>\n",
       "      <td>False</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.1760</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170650</th>\n",
       "      <td>False</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.2540</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170651</th>\n",
       "      <td>False</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>0.9130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170652</th>\n",
       "      <td>False</td>\n",
       "      <td>0.3430</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170653 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_billboard  liveness  acousticness  energy  speechiness  label\n",
       "0              False    0.1130        0.4010  0.5730       0.0544      1\n",
       "1              False    0.2720        0.2210  0.7220       0.0369      1\n",
       "2              False    0.0936        0.0112  0.7650       0.0993      1\n",
       "3              False    0.0824        0.0194  0.4540       0.3750      1\n",
       "4              False    0.0931        0.4680  0.8020       0.0878      1\n",
       "...              ...       ...           ...     ...          ...    ...\n",
       "170648         False    0.0979        0.9920  0.0082       0.0350      0\n",
       "170649         False    0.1050        0.1530  0.1760       0.9120      0\n",
       "170650         False    0.2740        0.9770  0.2540       0.1200      0\n",
       "170651         False    0.1070        0.1610  0.2380       0.9130      0\n",
       "170652         False    0.3430        0.7660  0.5740       0.0481      0\n",
       "\n",
       "[170653 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the features to keep\n",
    "features_to_keep = ['is_billboard', 'liveness', 'acousticness', 'energy', 'speechiness', 'label']\n",
    "\n",
    "# Drop all features except the ones to keep\n",
    "df34_clean = df34_old[features_to_keep]\n",
    "\n",
    "df34_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8023249000161147\n",
      "Test Accuracy: 0.7155664938032873\n",
      "Precision:  0.7045429301343996\n",
      "Recall:  0.7430010542345086\n",
      "F1:  0.7232611174458381\n",
      "Model Accuracy: 0.7155664938032873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df34_clean.drop('label', axis=1)\n",
    "y = df34_clean['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the KNN model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training set\n",
    "y_train_pred = knn.predict(X_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model for the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Calculate the accuracy of the model for the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the test set\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "print(\"Precision: \", precision)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "print(\"Recall: \", recall)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "# Calculate the overall accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned KNN Model:\n",
      "Accuracy: 0.7251765257390642\n",
      "Precision: 0.7125649243010277\n",
      "Recall: 0.7553004568349537\n",
      "F1 Score: 0.7333105879677015\n"
     ]
    }
   ],
   "source": [
    "#tuned Knn\n",
    "# Define the parameter grid\n",
    "param_grid = {'n_neighbors': [3, 5, 7],\n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'p': [1, 2]}\n",
    "\n",
    "# Create a KNN classifier\n",
    "knn_tuned = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(knn_tuned, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a new KNN classifier with the best hyperparameters\n",
    "best_knn = KNeighborsClassifier(**best_params)\n",
    "\n",
    "# Fit the model to the training data\n",
    "best_knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred)\n",
    "precision_tuned = precision_score(y_test, y_pred)\n",
    "recall_tuned = recall_score(y_test, y_pred)\n",
    "f1_tuned = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the results for the tuned model\n",
    "print(\"Tuned KNN Model:\")\n",
    "print(\"Accuracy:\", accuracy_tuned)\n",
    "print(\"Precision:\", precision_tuned)\n",
    "print(\"Recall:\", recall_tuned)\n",
    "print(\"F1 Score:\", f1_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "\n",
    "# Add labels, title, and axis ticks\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "plt.text(0.5, -0.2, f\"Accuracy: {accuracy:.2f}\", ha='center', transform=plt.gca().transAxes)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7407084572449861\n",
      "Test Accuracy: 0.7398845624212592\n",
      "Model Accuracy: 0.7405436763490827\n",
      "Precision: 0.7455951096727795\n",
      "Recall: 0.728651751200656\n",
      "F1 Score: 0.7370260663507109\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df34_clean.drop('label', axis=1)\n",
    "y = df34_clean['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the Logistic Regression model to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the training set\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model for the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Calculate the accuracy of the model for the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the test set\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy of the model\n",
    "overall_accuracy = accuracy_score(y, logreg.predict(X))\n",
    "print(\"Model Accuracy:\", overall_accuracy)\n",
    "\n",
    "# Print precision, recall, and F1 score\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elits\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\elits\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\elits\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\elits\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\elits\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.74081104        nan 0.74073779        nan 0.74073047]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Model:\n",
      "Accuracy: 0.740236148955495\n",
      "Precision: 0.7458662832494608\n",
      "Recall: 0.7291788684549607\n",
      "F1 Score: 0.7374281821951074\n"
     ]
    }
   ],
   "source": [
    "#tuned LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df34_clean.drop('label', axis=1)\n",
    "y = df34_clean['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.1, 1.0, 10.0],\n",
    "              'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a new Logistic Regression classifier with the best hyperparameters\n",
    "best_logreg = LogisticRegression(**best_params)\n",
    "\n",
    "# Fit the model to the training data\n",
    "best_logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = best_logreg.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Tuned Logistic Regression Model:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6672233453458732\n",
      "Precision: 0.6697351229362157\n",
      "Recall: 0.660477919643903\n",
      "F1 Score: 0.6650743099787687\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = df34_clean.drop('label', axis=1)\n",
    "y = df34_clean['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7410858164132313\n",
      "Precision: 0.7271022883926109\n",
      "Recall: 0.7722853461403303\n",
      "F1 Score: 0.7490130364395466\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = df34_clean.drop('label', axis=1)\n",
    "y = df34_clean['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7108786733468108\n",
      "Precision: 0.704437131184748\n",
      "Recall: 0.7271289680215532\n",
      "F1 Score: 0.7156032047956654\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = df34_clean.drop('label', axis=1)\n",
    "y = df34_clean['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform PCA to reduce dimensionality\n",
    "pca = PCA(n_components=2)  # Set the number of components to retain\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': ['auto']\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5)\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a new Random Forest classifier with the best hyperparameters\n",
    "best_rf_classifier = RandomForestClassifier(**best_params)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "best_rf_classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = best_rf_classifier.predict(X_test_pca)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
